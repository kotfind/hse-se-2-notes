== Схема страничной организации

Адресное пространство остается линейным

Разобьем логическое адресное пространство на *станицы* одинакового размера
(последняя страница недозаполнена)

`Логический адресс = Npage * size + offset`

Физическое адресное простарнство разбивается на *кадры* того же размера

`Физический адресс = Nframe * size + offset`

На этапе загрузки создаем отображение между кадрами и страницами. Для этого
*таблицей страниц* задаем функцию `Npage -> Nframe`. Обычно таблица хранится в PCB.

Есть внутренняя фрагментация: в среднем пол кадра на процесс

=== Работа Memory Management Unit

Логический адрес: `Npage | offset`

Физический адрес: `Nframe | offset`

Логический и физический offset-ы совпадают, `Npage` и `Nframe` сопоставляются по
таблице

В таблицу страниц можем добавить биты управления доступа (Read, Write, eXecute)

== Сегментно-страничная организация

Разобьем логическое пространство на сегменты, а каждый сегмент на страницы одинакового размера

Логический адрес: `Nseg, Np, poffset` --- номер сегмента, номер страницы, сдвиг
в странице

Физическое пространство разбиваем на кадры

Для каждого сегмента заводим свою таблицу страницы: `Np -> Nframe`

Для каждого процесса заводим таблицу сегментов: `Nseg -> (адрес таблицы страниц,
размер сегмента)`

Остается возможность в парадигме сегментов, небольшая фрагментация

== Многоуровневая таблица страниц

При больших размерах таблицы страниц её проблематично разместить в
последовательных кадрах памяти.

Заводим таблицу страниц для таблицы страниц

`Esize` --- размер страницы в таблице страниц процесса

`p = p1 * Esize + p2`

Логический адрес описывается тройкой: `(p1, p2, d)`

== Хешированная таблица страниц

Строим `HashMap: Npage -> Nframe`

== О производительности

На одно полезное обращение к памяти требуется несколько фактических.

Используется ассоциативная память, TLB (Translation Lookaside Buffer)

Записи TLB проверяются одновременно, а не последовательно

TLB очень быстрая, но маленькая

В TLB хранятся самые часто используемые ячейки

Если нужная ячейка в TLB не найдена, то происходит медленное обращение в память

В TLB хранит mapping: `(Npage, pid) -> Nframe`

=== Расчет времени

$t_0$ --- среднее время доступа к оперативной памяти

$t_1$ --- среднее время доступа к TLB. Обычно $t_1 << t_0$

$h$ --- вероятность наличия информации в TLB (hit ration). Обычно $>= 0.8$

Без TLB: $T = 3 t_0 underbrace(=, "при некоторых значениях") 300$

Двухуровневая страничная схема: $T = t_1 + h dot t_0 + (1 - h) dot 3 t_0 = 150 $

= Виртуальная память

== Концепция

+ Логическое адресное пространство разбито на куски и линейно-непрерывно раскидано
по физической

+ Связывания адресов происходит на этапе выполнения

+ Из принципа локальности сразу всё логическое пространство не используется. То,
что сейчас не используется переместим во вторичную память (например, на жесткий
диск)

+ Если нужного куска нет в памяти, то либо загружаем его в сводное место (при
наличии), либо загружаем вместо давно не использовавшегося куска

Преимущества:

+ Процесс не ограничен объемом физической памяти. Упрощается разработка
программ.

+ Повышается степень мультипрограммирования

+ Повышается эффективность swapping-а т.к. выталкивается не весь процесс, а
только некоторые его куски

== Как оно работает?

Делаем на примере страничной организации памяти

К битам управления доступом добавляем два бита:
- Бит наличия страницы в памяти
    - `1`: Просто используем `Nframe`
    - `0`: Возникает *исключительная ситуация* `page fault`

- (опционально) Бит модификации: была ли изменена страница, пока она лежала в
  оперативной памяти?

=== Обработка page fault

+ (hardware) Выполнение команды прекращается
+ (hardware) Сохраняется часть контекста. Управление передается по заранее
    определенному адресу
+ (software) Сохраняется оставшийся контекст
+ (software + hardware) Страница подкачивается в память, возможно замещая другую
    страницу
+ (software + hardware) Восстановление контекста. Повторное выполнение команды

== Стратегии управления

- Стратегия выборки --- когда подкачивать страницу?
    - По запросу --- когда возник page fault.
    - С упреждением --- при page fault подкачиваем не только данную страницу, но
      и соседние
- Стратегии размещения --- куда подкачать страницу, если есть пустое место?
    - First fit
    - Best fit
    - ...
- Стратегии замещения --- куда подкачать страницу, если пустых мест нет?

== Алгоритмы замещения

- *Локальные*: процессу заранее выделяются конкретные кадры
- *Глобальные*: можно использовать кадры других процессов

*Цель*: сократить количество page fault-ов

*Строка запросов* --- последовательность страниц, к которым мы обращались

*Сокращенная строка запросов* --- убираем последовательные повторы: `12223445 -> 12345`

=== FIFO

Выталкивается самая старая страница

=== Аномалия Belady

Для некоторых алгоритмов увеличение количества кадров приводит к увеличению
количества `page fault`-ов

== Стековые алгоритмы

Набор страницы в памяти для $N$ кадров есть подмножество страниц для $N + M$
кадров

Никогда не будет аномалии Belady
